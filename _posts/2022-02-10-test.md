---
layout: posts
title: "Reinforcement learning I: Markov Decision Process"
categories: reinforcement-learning
mathjax: true
header:
  image: /assets/images/splash.jpeg
  image_description: "Light"
---
Mở đầu series Reinforcement Learning (RL) bằng Markov Decision Process(es).

Chúng ta sẽ mô tả lại environment qua các thuộc tính:

* State: trạng thái của environment tại một thời điểm
* Action: Hành động của agent
* Reward: Phần thưởng tương ứng của mỗi state (Action không có reward, mà action sẽ đẩy environment sang state mới và state đó sinh reward).

### Markov Process
Một state *s* được coi là Markov state khi: Tương lai sinh ra từ state đó độc lập có điều kiện (conditionally independent) với quá khứ theo *s* đã biết.

$$ P(s_{t+1}|s_{t}) = P(s_{t+1}|s_1, s_2, ..., s_t) $$

Xác suất chuyển từ trạng thái s sang s' được xác định qua hàm state transition probability function:

$$ \mathrm{P}_{ss'}=P(s_{t+1}=s'|s_{t}=s) $$

$$ \mathrm{P}=\begin{bmatrix}p_{11} & ... & p_{1n} \\ ... & ... & ... \\ p_{n1} & ... & p_{nn} \end{bmatrix} $$

Markov process là một memory-less random process và có thể được mô tả qua tuple (S,P) với S là không gian trạng thái state space và P là state transition probability function.

### Markov Reward Process

Là Markov process với đánh giá thưởng phạt. Có thể định nghĩa Markov Reward Process (MRP) qua tuple (S, P, R, $ \gamma $) 